/**
 * IDL file for the low level vision system.
 *
 * $Id: LowLevelVisionSystem.idl,v 1.1 2004/07/21 09:35:12 stasse Exp $
 *
 * Copyright 2004 (c), JRL CNRS/AIST, Olivier Stasse.
 *
 * 2005/05/25   Modification to integrate SetImagesGrabbedSize
 * 2005/04/12   Modification to integrate GetImageIdentifier.
 * 2005/03/01   Modification to integrate Scene
 * 2004/12/02   Modification to integrate BREP
 * 2004/07/21   Ver 1.0 (First proposal)
 * 2004/07/01   Modification for real use.
 * 2003/12/18   For testing
 *
 */

#ifndef __LOW_LEVEL_VISION_SYSTEM_IDL__
#define __LOW_LEVEL_VISION_SYSTEM_IDL__

#ifndef __COMMON_IDL__
#include "common.idl"
#endif /* __COMMON_IDL__ */

#ifndef __VISION_SENSOR_IDL__
#include "visionsensor.idl"
#endif /* __VISION_SENSOR_IDL__ */

#include "BRep.idl"
#include "Scene.idl"
#include "StereoVision.idl"
#include "ModelTrackerInterface.idl"
#include "PointTrackerInterface.idl"
/**
 * Double buffer
 */
typedef sequence<double> DoubleBuffer;

/*
 * Interface for real cameras 
 */
interface HRP2Camera
{
  struct CameraParameter
  {
    long   type; /* Camera type */
    long         CameraId; /* Camera Identifier */
    string       CameraName; /* Camera Name */
    long         Width; /* Current Width */
    long         Height; /* Current Height */
    long         CalibrationWidth; /* Width of the image during calibration. */
    long         CalibrationHeight; /* Height of the image during calibration. */
  };

  struct IntrinsicParameters
  {
    float Focal; /* Focal of the camera */
    float Scale[2]; /* Scale of the pixel, 0 : X, 1 : Y */
    float SkewFactor; 
    float ImageCenter[2]; /* 0 : X, 1 : Y */
  };

  struct ProjectiveParameters
  {
    double ProjectiveMatrix[3][4]; /* P11 P12 P13 P14 P21 P22 P23 P24 P31 P32 P33 P34 */
    double RotationMatrix[3][3]; /* R11 R12 R13 R21 R22 R23 R31 R32 R33 */
    double PositionVector[3]; /* P1 P2 P3 */
    double IntrinsicMatrix[3][3]; /* I11 I12 I13 I21 I22 I23 I31 I32 I33 */
  };

  /** 
   * Get camera parameter 
   * @return camera parameter
   */
  CameraParameter
  GetCameraParameter();

  /** 
   * Get Camera Intrinsic Parameters
   */
  IntrinsicParameters
  GetIntrinsicParameters();

  /**
   * Change the size of acquisition
   */
  long 
  SetAcquisitionSize(in long aWidth, in long aHeight);
   

  /** 
   * Get Camera Projective Parameters
   */
  ProjectiveParameters
  GetProjectiveParameters();
  
};


/**
 * Sequence of Camera
 */
typedef sequence<HRP2Camera>	HRP2CameraSeq;

/**
 * Sequence of Processes
 */
typedef sequence<string> HRP2LowLevelVisionProcessesSeq;

/**
 * Sequence of Parameters
 */
typedef sequence<string> HRP2LowLevelVisionParametersSeq;

/**
 * Vision system interface for low level part.
 * - Get the frames from the vision system.
 */
interface LowLevelVisionSystem 
{
  enum DerivativeID
    { IDT, IDX, IDY, IDXDX, IDXDY, IDYDY, IDXDX2, IDXDY2, IDYDY2, IDXDT, IDYDT, IDT2, IDXDT2, IDYDT2 };

  enum InputMode
  { FRAMEGRABBER, FILES, FILESINGLE, SIMULATION};

  enum SynchroMode
  { SYNCHRO_FLOW, SYNCHRO_TRIGGER};

  enum DumpImageMode
    { NONE, SINGLE, FLOW};

  /** Vision Sensor exception
   * @member description description of the exception
   */
  exception VisionSensorException
  {
    string description;
  };

  /* Destruction
   */
  void destroy();

  /* Get the vision system s version
   * @return the version
   */
  long GetVersion();
  
  /* Start the main data-flow process. */
  long StartMainProcess();

  /* Stop the main data-flow process. */
  long StopMainProcess();

  /* Start a visual process using its name. */
  long StartProcess(in string ProcessName);

  /* Stop a visual process using its name. */
  long StopProcess(in string ProcessName);

  /* Get the status of a process. */
  long ProcessStatus(in string ProcessName);

  /* Returns the input mode:
   * FRAMEGRABBER: from the real robot,
   * FILES: from files included in a directory,
   * FILESINGLE: from a unique file,
   * SIMULATION: from OpenHRP.
   */
  InputMode GetInputMode();

  /* Returns the synchronization mode:
   * SYNCHRO_TRIGGER: through the user triggering,
   * SYNCHRO_FLOW: follow the flow of images.
   */
  SynchroMode SynchronizationMode();

  /* SYNCHRO_TRIGGER: through the user triggering,
   * SYNCHRO_FLOW: follow the flow of images.
   */
  void SetSynchronizationMode(in SynchroMode aSynchronizationMode);

  /* In some case, for instance simulation, it is necessary
     to be able to provide the image which will be processed.
     This is used by the plugin visionforLLVS to fill in the images
     from OpenHRP.
  */
  long SetImage(in ColorBuffer aColorBuffer, in long CameraID,
		in long aWidth, in long aHeight);

  /*  Set the grabbed image size for CameraID
   */
  long SetImagesGrabbedSize(in long CameraID, in long NewWidth, in long NewHeight);

  /* Trigger an image grabbing, only if synchronization mode is SYNCHRO_TRIGGER.
   * The server performs the operation on the current image, and waits
   * for the next image.
   * The minimal time between two image grabbing is 10 ms.
   */
  long TriggerSynchro();
  
  /* Get the camera sequence 
   * @param cameraSeq cameras
   * @return number of cameras
   */
  long getCameraSeq( out HRP2CameraSeq cameras );

  /* Get the original image given by one camera 
   * @param SemanticCamera : semantic identifier of a camera.
   * @param anImage: The image of the camera.
   * @param Format:  The current supported format is "GrayScaleChar".
   * The pixels are ordered by rows, the gray intensity is coded on 8 bits.
   * If the format given in arguments is not good,
   * the default one is used and specified in Format.
   * @return The number of points of the image.
   */
  long getImage(in long SemanticCamera, out ImageData anImage, inout string Format);

  /* Get the image given by one camera on which an edge detector has been applied
   * @param SemanticCamera : semantic identifier of a camera.
   * @param anImage: The image of the camera.
   * @param Format:  The current supported format is "GrayScaleChar".
   * The pixels are ordered by rows, the gray intensity is coded on 8 bits.
   * If the format given in arguments is not good,
   * the default one is used and specified in Format.
   * @return The number of points of the image.
   */
  long getEdgeImage(in long SemanticCamera, out ImageData anImage, inout string Format);

  /* Get the rectified image using the calibration parameters.
   * @param SemanticCamera : semantic identifier of a camera.
   * @param anImage: The rectified Image.
   * @param Format:  The current supported format is "GrayScaleChar".
   * The pixels are ordered by rows, the gray intensity is coded on 8 bits.
   * If the format given in arguments is not good,
   * the default one is used and specified in Format.
   * @return The number of points of the image.
   */
  long getRectifiedImage(in long SemanticCamera, out ImageData anImage, inout string Format);

  /* Get a range map. 
   * @param aRangeMap: An array of 3D points.
   * @param Format: The current format is "XYZGrayScaleChar", with 3 flots for X, Y and Z,
   * and the gray intensity corresponding to the 3D points.
   * @return The number of 3D points.
   */
  long getRangeMap(out RangeMap aRangeMap, inout string Format);

  /* Get the derivative corresponding 
   * to a given camera.
   * @param CameraID : identifier of a camera,
   * @param DerivativeID : identifier of the derivative.
   * @param ImageDerivative: the image derivative, the format is 
   * rows of floats. 
   * @param Width: The width of the image derivative (can be different from 
   * the initial image because of the mask used).
   * @param Height: The height of the image deritvative (can be different
   * from the initial image because of the mask used).
   * @return the size of the image.
   */
  long getImageDerivative(in long CameraID, in long DerivativeID, out FloatBuffer ImageDerivative, 
			  out long Width, out long Height);

  /* Get the optical flow for a given camera.
   * @param CameraID: identifier of a camera.
   * @param OpticalFlow: vectors of the motion in the image.
   * @param Confidence: confidence value on the computed optical flow.
   * @param Width: The width of the optical flows (can be different from 
   * the initial image because of the mask used).
   * @param Height: The height of the optical flows (can be different
   * from the initial image because of the mask used).
   * @return 0 is everything went well, -1 otherwise.
   */
  long getOpticalFlow(in long CameraID, out FloatBuffer OpticalFlow, out FloatBuffer Confidence,
		      out long Width, out long Height);

  /* Get the harris detector (Feature points) for a given camera.
   * @param CameraID: identifier of a camera.
   * @param Harris: Vector of the harris detector in the image.
   * @param Width: The width of the harris detector (can be different from 
   * the initial image because of the mask used).
   * @param Height: The height of the harris detector (can be different
   * from the initial image because of the mask used).
   */ 
  long getHarrisDetector(in long CameraId, out FloatBuffer Harris,
			 out long Width, out long Height);


  /* Get the vision process sequence.
   * @param ProcessesSeq: Sequence of strings for each process' name.
   * @return The number of visual processes.
   */
  long getLowLevelVisionProcesses(out HRP2LowLevelVisionProcessesSeq ProcessesSeq);
  
  /* Set the value of a parameter for a given process.
   * @param aProcessName: Name of the process.
   * @param aParameter: Name of the parameter.
   * @param aValue: Value of the parameter.
   */
  void SetAProcessParameterAndValue(in string aProcessName, in string aParameter, in string aValue);

  /* Get the value for a parameter available for a process.
   * @param aProcessName : Name of the process.
   * @param ParameterName: Name of the parameter.
   * @param ParameterValue: Value of the parameter.
   */
  long GetProcessParameter(in string aProcessName, 
			    in string aParameterName,
			    out string ParameterValue);

  /* Get the parameters available for a process.
   * @param aProcessName : Name of the process.
   * @param ParametersSeq: Sequence of the parameters.
   * @param ParametersValueSeq: Sequence of the parameters' value.
   */
  long GetProcessParameters(in string aProcessName, 
			    out HRP2LowLevelVisionParametersSeq ParametersSeq,
			    out HRP2LowLevelVisionParametersSeq ParametersValueSeq);

  /* Set the dump image mode.
   * @param aDumpImageMode: may be one of the three values listed in the DumpImageMode.
   */
  void SetDumpImageMode( in DumpImageMode aDumpImageMode,
			 in FloatBuffer Informations, 
			 in long SizeOfInformations);

  /* Get the dump image mode.
   * @return the dump image mode cf below.
   */
  DumpImageMode GetDumpImageMode();

  /* Get the matrix to go from the Vision system reference
   * frame to the head. 
   */
  long GetMatrixHeadTOrg(out DoubleBuffer HeadTOrg);

  /* ! Get the boundary representation of the current image
   */
  long GetBoundaryRepresentation(out CBREPSeq aBrep);

  /* ! Get the scene object inside the Single Camera SLAM
   * vision process
   */
  long GetSceneObject(out SceneObject aSceneObject);

  /* Function to delete a feature on the remote CORBA server */
  void SceneDeleteFeature(in long FeatureLabel);

  /* Returns the image identifier */
  long GetImageIdentifier();

  /* Returns the StereoVision object */
  StereoVision getStereoVision();

  /* Retuns the Model tracker object. */
  ModelTrackerInterface getModelTracker();

  /* Retuns the Model tracker object. */
  PointTrackerInterface getPointTracker();
};


#endif
